# Available Models as of June 21, 2025

## Main Models

| Provider    | Model Name                                     | SWE Score | Input Cost | Output Cost |
| ----------- | ---------------------------------------------- | --------- | ---------- | ----------- |
| bedrock     | us.anthropic.claude-3-7-sonnet-20250219-v1:0   | 0.623     | 3          | 15          |
| anthropic   | claude-sonnet-4-20250514                       | 0.727     | 3          | 15          |
| anthropic   | claude-opus-4-20250514                         | 0.725     | 15         | 75          |
| anthropic   | claude-3-7-sonnet-20250219                     | 0.623     | 3          | 15          |
| anthropic   | claude-3-5-sonnet-20241022                     | 0.49      | 3          | 15          |
| azure       | gpt-4o                                         | 0.332     | 2.5        | 10          |
| azure       | gpt-4o-mini                                    | 0.3       | 0.15       | 0.6         |
| azure       | gpt-4-1                                        | —         | 2          | 10          |
| openai      | gpt-4o                                         | 0.332     | 2.5        | 10          |
| openai      | o1                                             | 0.489     | 15         | 60          |
| openai      | o3                                             | 0.5       | 2          | 8           |
| openai      | o3-mini                                        | 0.493     | 1.1        | 4.4         |
| openai      | o4-mini                                        | 0.45      | 1.1        | 4.4         |
| openai      | o1-mini                                        | 0.4       | 1.1        | 4.4         |
| openai      | o1-pro                                         | —         | 150        | 600         |
| openai      | gpt-4-5-preview                                | 0.38      | 75         | 150         |
| openai      | gpt-4-1-mini                                   | —         | 0.4        | 1.6         |
| openai      | gpt-4-1-nano                                   | —         | 0.1        | 0.4         |
| openai      | gpt-4o-mini                                    | 0.3       | 0.15       | 0.6         |
| google      | gemini-2.5-pro-preview-05-06                   | 0.638     | —          | —           |
| google      | gemini-2.5-pro-preview-03-25                   | 0.638     | —          | —           |
| google      | gemini-2.5-flash-preview-04-17                 | 0.604     | —          | —           |
| google      | gemini-2.0-flash                               | 0.518     | 0.15       | 0.6         |
| google      | gemini-2.0-flash-lite                          | —         | —          | —           |
| perplexity  | sonar-pro                                      | —         | 3          | 15          |
| perplexity  | sonar-reasoning-pro                            | 0.211     | 2          | 8           |
| perplexity  | sonar-reasoning                                | 0.211     | 1          | 5           |
| xai         | grok-3                                         | —         | 3          | 15          |
| xai         | grok-3-fast                                    | —         | 5          | 25          |
| ollama      | devstral:latest                                | —         | 0          | 0           |
| ollama      | qwen3:latest                                   | —         | 0          | 0           |
| ollama      | qwen3:14b                                      | —         | 0          | 0           |
| ollama      | qwen3:32b                                      | —         | 0          | 0           |
| ollama      | mistral-small3.1:latest                        | —         | 0          | 0           |
| ollama      | llama3.3:latest                                | —         | 0          | 0           |
| ollama      | phi4:latest                                    | —         | 0          | 0           |
| openrouter  | google/gemini-2.5-flash-preview-05-20          | —         | 0.15       | 0.6         |
| openrouter  | google/gemini-2.5-flash-preview-05-20:thinking | —         | 0.15       | 3.5         |
| openrouter  | google/gemini-2.5-pro-exp-03-25                | —         | 0          | 0           |
| openrouter  | deepseek/deepseek-chat-v3-0324:free            | —         | 0          | 0           |
| openrouter  | deepseek/deepseek-chat-v3-0324                 | —         | 0.27       | 1.1         |
| openrouter  | openai/gpt-4.1                                 | —         | 2          | 8           |
| openrouter  | openai/gpt-4.1-mini                            | —         | 0.4        | 1.6         |
| openrouter  | openai/gpt-4.1-nano                            | —         | 0.1        | 0.4         |
| openrouter  | openai/o3                                      | —         | 10         | 40          |
| openrouter  | openai/codex-mini                              | —         | 1.5        | 6           |
| openrouter  | openai/gpt-4o-mini                             | —         | 0.15       | 0.6         |
| openrouter  | openai/o4-mini                                 | 0.45      | 1.1        | 4.4         |
| openrouter  | openai/o4-mini-high                            | —         | 1.1        | 4.4         |
| openrouter  | openai/o1-pro                                  | —         | 150        | 600         |
| openrouter  | meta-llama/llama-3.3-70b-instruct              | —         | 120        | 600         |
| openrouter  | meta-llama/llama-4-maverick                    | —         | 0.18       | 0.6         |
| openrouter  | meta-llama/llama-4-scout                       | —         | 0.08       | 0.3         |
| openrouter  | qwen/qwen-max                                  | —         | 1.6        | 6.4         |
| openrouter  | qwen/qwen-turbo                                | —         | 0.05       | 0.2         |
| openrouter  | qwen/qwen3-235b-a22b                           | —         | 0.14       | 2           |
| openrouter  | mistralai/mistral-small-3.1-24b-instruct:free  | —         | 0          | 0           |
| openrouter  | mistralai/mistral-small-3.1-24b-instruct       | —         | 0.1        | 0.3         |
| openrouter  | mistralai/devstral-small                       | —         | 0.1        | 0.3         |
| openrouter  | mistralai/mistral-nemo                         | —         | 0.03       | 0.07        |
| openrouter  | thudm/glm-4-32b:free                           | —         | 0          | 0           |
| claude-code | opus                                           | 0.725     | 0          | 0           |
| claude-code | sonnet                                         | 0.727     | 0          | 0           |

## Research Models

| Provider    | Model Name                 | SWE Score | Input Cost | Output Cost |
| ----------- | -------------------------- | --------- | ---------- | ----------- |
| bedrock     | us.deepseek.r1-v1:0        | —         | 1.35       | 5.4         |
| openai      | gpt-4o-search-preview      | 0.33      | 2.5        | 10          |
| openai      | gpt-4o-mini-search-preview | 0.3       | 0.15       | 0.6         |
| perplexity  | sonar-pro                  | —         | 3          | 15          |
| perplexity  | sonar                      | —         | 1          | 1           |
| perplexity  | deep-research              | 0.211     | 2          | 8           |
| perplexity  | sonar-reasoning-pro        | 0.211     | 2          | 8           |
| perplexity  | sonar-reasoning            | 0.211     | 1          | 5           |
| xai         | grok-3                     | —         | 3          | 15          |
| xai         | grok-3-fast                | —         | 5          | 25          |
| claude-code | opus                       | 0.725     | 0          | 0           |
| claude-code | sonnet                     | 0.727     | 0          | 0           |

## Fallback Models

| Provider    | Model Name                                     | SWE Score | Input Cost | Output Cost |
| ----------- | ---------------------------------------------- | --------- | ---------- | ----------- |
| bedrock     | us.anthropic.claude-3-7-sonnet-20250219-v1:0   | 0.623     | 3          | 15          |
| anthropic   | claude-sonnet-4-20250514                       | 0.727     | 3          | 15          |
| anthropic   | claude-opus-4-20250514                         | 0.725     | 15         | 75          |
| anthropic   | claude-3-7-sonnet-20250219                     | 0.623     | 3          | 15          |
| anthropic   | claude-3-5-sonnet-20241022                     | 0.49      | 3          | 15          |
| azure       | gpt-4o                                         | 0.332     | 2.5        | 10          |
| azure       | gpt-4o-mini                                    | 0.3       | 0.15       | 0.6         |
| azure       | gpt-4-1                                        | —         | 2          | 10          |
| openai      | gpt-4o                                         | 0.332     | 2.5        | 10          |
| openai      | o3                                             | 0.5       | 2          | 8           |
| openai      | o4-mini                                        | 0.45      | 1.1        | 4.4         |
| google      | gemini-2.5-pro-preview-05-06                   | 0.638     | —          | —           |
| google      | gemini-2.5-pro-preview-03-25                   | 0.638     | —          | —           |
| google      | gemini-2.5-flash-preview-04-17                 | 0.604     | —          | —           |
| google      | gemini-2.0-flash                               | 0.518     | 0.15       | 0.6         |
| google      | gemini-2.0-flash-lite                          | —         | —          | —           |
| perplexity  | sonar-reasoning-pro                            | 0.211     | 2          | 8           |
| perplexity  | sonar-reasoning                                | 0.211     | 1          | 5           |
| xai         | grok-3                                         | —         | 3          | 15          |
| xai         | grok-3-fast                                    | —         | 5          | 25          |
| ollama      | devstral:latest                                | —         | 0          | 0           |
| ollama      | qwen3:latest                                   | —         | 0          | 0           |
| ollama      | qwen3:14b                                      | —         | 0          | 0           |
| ollama      | qwen3:32b                                      | —         | 0          | 0           |
| ollama      | mistral-small3.1:latest                        | —         | 0          | 0           |
| ollama      | llama3.3:latest                                | —         | 0          | 0           |
| ollama      | phi4:latest                                    | —         | 0          | 0           |
| openrouter  | google/gemini-2.5-flash-preview-05-20          | —         | 0.15       | 0.6         |
| openrouter  | google/gemini-2.5-flash-preview-05-20:thinking | —         | 0.15       | 3.5         |
| openrouter  | google/gemini-2.5-pro-exp-03-25                | —         | 0          | 0           |
| openrouter  | deepseek/deepseek-chat-v3-0324:free            | —         | 0          | 0           |
| openrouter  | openai/gpt-4.1                                 | —         | 2          | 8           |
| openrouter  | openai/gpt-4.1-mini                            | —         | 0.4        | 1.6         |
| openrouter  | openai/gpt-4.1-nano                            | —         | 0.1        | 0.4         |
| openrouter  | openai/o3                                      | —         | 10         | 40          |
| openrouter  | openai/codex-mini                              | —         | 1.5        | 6           |
| openrouter  | openai/gpt-4o-mini                             | —         | 0.15       | 0.6         |
| openrouter  | openai/o4-mini                                 | 0.45      | 1.1        | 4.4         |
| openrouter  | openai/o4-mini-high                            | —         | 1.1        | 4.4         |
| openrouter  | openai/o1-pro                                  | —         | 150        | 600         |
| openrouter  | meta-llama/llama-3.3-70b-instruct              | —         | 120        | 600         |
| openrouter  | meta-llama/llama-4-maverick                    | —         | 0.18       | 0.6         |
| openrouter  | meta-llama/llama-4-scout                       | —         | 0.08       | 0.3         |
| openrouter  | qwen/qwen-max                                  | —         | 1.6        | 6.4         |
| openrouter  | qwen/qwen-turbo                                | —         | 0.05       | 0.2         |
| openrouter  | qwen/qwen3-235b-a22b                           | —         | 0.14       | 2           |
| openrouter  | mistralai/mistral-small-3.1-24b-instruct:free  | —         | 0          | 0           |
| openrouter  | mistralai/mistral-small-3.1-24b-instruct       | —         | 0.1        | 0.3         |
| openrouter  | mistralai/mistral-nemo                         | —         | 0.03       | 0.07        |
| openrouter  | thudm/glm-4-32b:free                           | —         | 0          | 0           |
| claude-code | opus                                           | 0.725     | 0          | 0           |
| claude-code | sonnet                                         | 0.727     | 0          | 0           |

## Deepseek Models

Deepseek provides OpenAI-compatible API with the following model:

| Model | Description | Context Window | Best For |
|-------|-------------|---------------|----------|
| `deepseek/deepseek-reasoner` | Advanced reasoning model with chain-of-thought | 64K | Complex reasoning, math problems |

### Usage

To use Deepseek models, you need to:

1. Obtain a Deepseek API key from [Deepseek Platform](https://platform.deepseek.com/)
2. Add your API key to the MCP configuration:
   ```json
   "DEEPSEEK_API_KEY": "your-api-key-here"
   ```
3. Set your preferred model:
   ```
   Change the main model to deepseek/deepseek-reasoner
   ```
   or
   ```
   Change the research model to deepseek/deepseek-reasoner
   ```

### Features

- **JSON Output**: Force structured JSON responses by setting `response_format` to `{"type": "json_object"}`
- **Function Calling**: Similar to OpenAI's function calling
- **Context Caching**: Automatic caching of repeated context to reduce token costs

### Pricing

Pricing is based on input and output tokens:
- deepseek-reasoner: ¥4/million input tokens, ¥16/million output tokens

Off-peak discounts available from 00:30-08:30 Beijing time.

## Doubao (火山方舟) Models

Doubao (火山方舟) provides OpenAI-compatible API with the following models:

| Model | Description | Context Window | Best For |
|-------|-------------|---------------|----------|
| `doubao/doubao-seed-1.6-250615` | Latest Doubao seed model | 8K | General chat, coding, reasoning |
| `doubao/ep-20250629060919-64pkc` | Endpoint model (example) | 8K | General chat, coding, reasoning |

### Usage

To use Doubao models, you need to:

1. Obtain an ARK API key from [火山方舟控制台](https://ark.volcengine.com/)
2. Add your API key to the MCP configuration:
   ```json
   "ARK_API_KEY": "your-api-key-here"
   ```
3. Set your preferred model:
   ```
   Change the main model to doubao/doubao-seed-1.6-250615
   ```
   or
   ```
   Change the research model to doubao/doubao-seed-1.6-250615
   ```

### Features

- **OpenAI Compatible**: Uses the same API format as OpenAI
- **Multimodal Support**: Can process both text and images
- **Function Calling**: Supports OpenAI-style function calling
- **Application Layer Encryption**: Optional encryption for secure inference

### API Details

- **Base URL**: `https://ark.cn-beijing.volces.com/api/v3`
- **Authentication**: Bearer Token (`Authorization: Bearer $ARK_API_KEY`)
